{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Langgraph - Short Term and Long Term memory examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All packages imported successfully!\n"
     ]
    }
   ],
   "source": [
    "# Standard library imports\n",
    "import os\n",
    "import json\n",
    "import uuid\n",
    "from datetime import datetime\n",
    "from typing import TypedDict, Annotated, Sequence, Optional, List, Dict, Any, Tuple\n",
    "from operator import add\n",
    "\n",
    "# Snowflake imports\n",
    "import snowflake.connector\n",
    "from snowflake.connector import DictCursor\n",
    "\n",
    "# LangGraph imports\n",
    "from langgraph.graph import StateGraph, START, END, MessagesState\n",
    "from langgraph.checkpoint.memory import InMemorySaver\n",
    "from langgraph.checkpoint.base import BaseCheckpointSaver, Checkpoint, CheckpointTuple\n",
    "from langgraph.store.memory import InMemoryStore\n",
    "from langgraph.store.base import BaseStore, Item\n",
    "from langgraph.graph.message import add_messages\n",
    "# LangChain imports\n",
    "from langchain_core.messages import HumanMessage, AIMessage, SystemMessage, RemoveMessage\n",
    "from langchain_core.runnables import RunnableConfig\n",
    "from langchain_core.messages.utils import trim_messages\n",
    "\n",
    "# For environment variables\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "print(\"All packages imported successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to Snowflake successfully!\n",
      "   Version: 9.33.1\n",
      "   Database: LAB_DB\n",
      "   Schema: PUBLIC\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# SNOWFLAKE CONNECTION SETUP\n",
    "# ============================================================================\n",
    "\n",
    "# Load environment variables (if using .env file)\n",
    "load_dotenv()\n",
    "\n",
    "# Snowflake connection parameters\n",
    "SNOWFLAKE_CONFIG = {\n",
    "    'user': os.getenv('SNOWFLAKE_USER'),\n",
    "    'password': os.getenv('SNOWFLAKE_PASSWORD'),\n",
    "    'account': os.getenv('SNOWFLAKE_ACCOUNT'),\n",
    "    'warehouse': os.getenv('SNOWFLAKE_WAREHOUSE'),\n",
    "    'database': os.getenv('SNOWFLAKE_DATABASE'),\n",
    "    'schema': os.getenv('SNOWFLAKE_SCHEMA'),\n",
    "    'role': os.getenv('SNOWFLAKE_ROLE')\n",
    "}\n",
    "\n",
    "def get_snowflake_connection():\n",
    "    \"\"\"\n",
    "    Create and return a Snowflake connection.\n",
    "    \n",
    "    Returns:\n",
    "        snowflake.connector.connection: Active Snowflake connection\n",
    "    \"\"\"\n",
    "    try:\n",
    "        conn = snowflake.connector.connect(\n",
    "            user=SNOWFLAKE_CONFIG['user'],\n",
    "            password=SNOWFLAKE_CONFIG['password'],\n",
    "            account=SNOWFLAKE_CONFIG['account'],\n",
    "            warehouse=SNOWFLAKE_CONFIG['warehouse'],\n",
    "            database=SNOWFLAKE_CONFIG['database'],\n",
    "            schema=SNOWFLAKE_CONFIG['schema'],\n",
    "            role=SNOWFLAKE_CONFIG['role']\n",
    "        )\n",
    "        return conn\n",
    "    except Exception as e:\n",
    "        print(f\"Error connecting to Snowflake: {e}\")\n",
    "        raise\n",
    "\n",
    "# Test the connection\n",
    "try:\n",
    "    test_conn = get_snowflake_connection()\n",
    "    cursor = test_conn.cursor()\n",
    "    cursor.execute(\"SELECT CURRENT_VERSION()\")\n",
    "    version = cursor.fetchone()[0]\n",
    "    print(f\"Connected to Snowflake successfully!\")\n",
    "    print(f\"   Version: {version}\")\n",
    "    print(f\"   Database: {SNOWFLAKE_CONFIG['database']}\")\n",
    "    print(f\"   Schema: {SNOWFLAKE_CONFIG['schema']}\")\n",
    "    cursor.close()\n",
    "    test_conn.close()\n",
    "except Exception as e:\n",
    "    print(f\"Connection test failed: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Snowflake Cortex LLM initialized with STRING prompt format!\n",
      "   Model: llama3.1-70b\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# SNOWFLAKE CORTEX LLM - WITH OPTIONS FORMAT\n",
    "# ============================================================================\n",
    "\n",
    "class SnowflakeCortexLLM:\n",
    "    \"\"\"\n",
    "    Wrapper for Snowflake Cortex LLM (COMPLETE function).\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, model: str = \"llama3.1-70b\"):\n",
    "        self.model = model\n",
    "        self.connection = None\n",
    "    \n",
    "    def _get_connection(self):\n",
    "        \"\"\"Get or create Snowflake connection.\"\"\"\n",
    "        if self.connection is None or self.connection.is_closed():\n",
    "            self.connection = get_snowflake_connection()\n",
    "        return self.connection\n",
    "    \n",
    "    def invoke(self, messages: List[Any]) -> AIMessage:\n",
    "        \"\"\"\n",
    "        Invoke the LLM with messages.\n",
    "        \"\"\"\n",
    "        # Convert messages to a single prompt string for simplicity\n",
    "        prompt_parts = []\n",
    "        for msg in messages:\n",
    "            if isinstance(msg, HumanMessage):\n",
    "                prompt_parts.append(f\"User: {msg.content}\")\n",
    "            elif isinstance(msg, AIMessage):\n",
    "                prompt_parts.append(f\"Assistant: {msg.content}\")\n",
    "            elif isinstance(msg, SystemMessage):\n",
    "                prompt_parts.append(f\"System: {msg.content}\")\n",
    "            elif isinstance(msg, dict):\n",
    "                role = msg.get('role', 'user')\n",
    "                content = msg.get('content', '')\n",
    "                prompt_parts.append(f\"{role.capitalize()}: {content}\")\n",
    "        \n",
    "        prompt_parts.append(\"Assistant:\")  # Prompt for response\n",
    "        full_prompt = \"\\n\".join(prompt_parts)\n",
    "        \n",
    "        try:\n",
    "            conn = self._get_connection()\n",
    "            cursor = conn.cursor(DictCursor)\n",
    "            \n",
    "            # Simple string prompt version\n",
    "            query = \"SELECT SNOWFLAKE.CORTEX.COMPLETE(%s, %s) as response\"\n",
    "            \n",
    "            cursor.execute(query, (self.model, full_prompt))\n",
    "            result = cursor.fetchone()\n",
    "            cursor.close()\n",
    "            \n",
    "            # Extract response\n",
    "            response_text = result['RESPONSE']\n",
    "            \n",
    "            return AIMessage(content=response_text)\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"Error calling Snowflake Cortex: {e}\")\n",
    "            print(f\"Prompt sent: {full_prompt[:200]}...\")\n",
    "            raise\n",
    "    \n",
    "    def __del__(self):\n",
    "        \"\"\"Close connection when object is destroyed.\"\"\"\n",
    "        if self.connection and not self.connection.is_closed():\n",
    "            self.connection.close()\n",
    "\n",
    "# Re-initialize the LLM\n",
    "llm = SnowflakeCortexLLM(model=\"llama3.1-70b\")\n",
    "\n",
    "print(\"Snowflake Cortex LLM initialized with STRING prompt format!\")\n",
    "print(f\"   Model: llama3.1-70b\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Snowflake Cortex LLM with string prompt...\n",
      "\n",
      "LLM Response:\n",
      "   Hello from Snowflake!\n"
     ]
    }
   ],
   "source": [
    "# Test the LLM\n",
    "print(\"Testing Snowflake Cortex LLM with string prompt...\")\n",
    "\n",
    "test_messages = [\n",
    "    HumanMessage(content=\"Say 'Hello from Snowflake!' if you can hear me.\")\n",
    "]\n",
    "\n",
    "try:\n",
    "    response = llm.invoke(test_messages)\n",
    "    print(f\"\\nLLM Response:\")\n",
    "    print(f\"   {response.content}\")\n",
    "except Exception as e:\n",
    "    print(f\" Test failed: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Helper functions defined!\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# HELPER FUNCTIONS\n",
    "# ============================================================================\n",
    "\n",
    "def print_messages(messages: List[Any], title: str = \"Messages\"):\n",
    "    \"\"\"\n",
    "    Pretty print messages.\n",
    "    \n",
    "    Args:\n",
    "        messages: List of messages\n",
    "        title: Title for the output\n",
    "    \"\"\"\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"{title}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    for i, msg in enumerate(messages, 1):\n",
    "        role = \"Unknown\"\n",
    "        content = \"\"\n",
    "        \n",
    "        if isinstance(msg, HumanMessage):\n",
    "            role = \"ðŸ‘¤ User\"\n",
    "            content = msg.content\n",
    "        elif isinstance(msg, AIMessage):\n",
    "            role = \"ðŸ¤– Assistant\"\n",
    "            content = msg.content\n",
    "        elif isinstance(msg, SystemMessage):\n",
    "            role = \"âš™ï¸  System\"\n",
    "            content = msg.content\n",
    "        elif isinstance(msg, dict):\n",
    "            role = msg.get('role', 'Unknown')\n",
    "            content = msg.get('content', '')\n",
    "        \n",
    "        print(f\"\\n{i}. {role}:\")\n",
    "        print(f\"   {content}\")\n",
    "    \n",
    "    print(f\"\\n{'='*60}\\n\")\n",
    "\n",
    "\n",
    "def execute_snowflake_query(query: str, fetch: bool = True) -> Optional[List[Dict]]:\n",
    "    \"\"\"\n",
    "    Execute a Snowflake query and optionally fetch results.\n",
    "    \n",
    "    Args:\n",
    "        query: SQL query to execute\n",
    "        fetch: Whether to fetch results (default: True)\n",
    "    \n",
    "    Returns:\n",
    "        List of results as dictionaries, or None if fetch=False\n",
    "    \"\"\"\n",
    "    conn = get_snowflake_connection()\n",
    "    cursor = conn.cursor(DictCursor)\n",
    "    \n",
    "    try:\n",
    "        cursor.execute(query)\n",
    "        \n",
    "        if fetch:\n",
    "            results = cursor.fetchall()\n",
    "            cursor.close()\n",
    "            conn.close()\n",
    "            return results\n",
    "        else:\n",
    "            conn.commit()\n",
    "            cursor.close()\n",
    "            conn.close()\n",
    "            return None\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Query execution error: {e}\")\n",
    "        cursor.close()\n",
    "        conn.close()\n",
    "        raise\n",
    "\n",
    "print(\"Helper functions defined!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# SECTION 1: SHORT-TERM MEMORY (Thread-scoped)\n",
    "# ============================================================================\n",
    "# \n",
    "# Short-term memory allows an agent to remember the conversation within\n",
    "# a single session/thread. This is essential for multi-turn conversations.\n",
    "#\n",
    "# Key Concepts:\n",
    "# - Thread: A unique conversation session (identified by thread_id)\n",
    "# - Checkpoint: A snapshot of the conversation state at a specific point\n",
    "# - Checkpointer: Stores and retrieves checkpoints\n",
    "# ============================================================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "DEMO 1.1: Agent WITHOUT Memory\n",
      "======================================================================\n",
      "\n",
      "Let's see what happens when an agent has NO memory...\n",
      "\n",
      "Graph built WITHOUT checkpointer (no memory)\n",
      "\n",
      "Let's have a conversation...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# 1.1 PROBLEM: Agent Without Memory\n",
    "# ============================================================================\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"DEMO 1.1: Agent WITHOUT Memory\")\n",
    "print(\"=\"*70)\n",
    "print(\"\\nLet's see what happens when an agent has NO memory...\\n\")\n",
    "\n",
    "# Define a simple state\n",
    "class State(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "\n",
    "# Define the chatbot node\n",
    "def chatbot_node(state: State) -> State:\n",
    "    \"\"\"\n",
    "    Simple chatbot that responds using Snowflake Cortex.\n",
    "    \"\"\"\n",
    "    messages = state[\"messages\"]\n",
    "    response = llm.invoke(messages)\n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "# Build the graph WITHOUT checkpointer\n",
    "builder = StateGraph(State)\n",
    "builder.add_node(\"chatbot\", chatbot_node)\n",
    "builder.add_edge(START, \"chatbot\")\n",
    "builder.add_edge(\"chatbot\", END)\n",
    "\n",
    "# Compile WITHOUT checkpointer (no memory!)\n",
    "graph_no_memory = builder.compile()\n",
    "\n",
    "print(\"Graph built WITHOUT checkpointer (no memory)\")\n",
    "print(\"\\nLet's have a conversation...\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------\n",
      "USER: My name is Ram and I'm a Data Engineer\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "BOT: Nice to meet you, Ram! As a Data Engineer, I'm sure you're no stranger to working with large datasets, designing data pipelines, and building scalable data architectures. What kind of projects have you been working on lately? Are you more focused on cloud-based data engineering (e.g. AWS, GCP, Azure) or on-premises solutions?\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# First message: Introduce yourself\n",
    "print(\"-\" * 70)\n",
    "print(\"USER: My name is Ram and I'm a Data Engineer\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "response1 = graph_no_memory.invoke({\n",
    "    \"messages\": [HumanMessage(content=\"My name is Ram and I'm a Data Engineer\")]\n",
    "})\n",
    "\n",
    "print(f\"\\nBOT: {response1['messages'][-1].content}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------\n",
      "USER: What's my name?\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "BOT: I don't know your name. This is the beginning of our conversation, and I don't have any information about you. Would you like to tell me your name?\n",
      "\n",
      "âŒ PROBLEM: The bot doesn't remember your name!\n",
      "   Each invocation is independent - no conversation history.\n"
     ]
    }
   ],
   "source": [
    "# Second message: Ask about the name\n",
    "print(\"-\" * 70)\n",
    "print(\"USER: What's my name?\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "response2 = graph_no_memory.invoke({\n",
    "    \"messages\": [HumanMessage(content=\"What's my name?\")]\n",
    "})\n",
    "\n",
    "print(f\"\\nBOT: {response2['messages'][-1].content}\\n\")\n",
    "\n",
    "print(\"âŒ PROBLEM: The bot doesn't remember your name!\")\n",
    "print(\"   Each invocation is independent - no conversation history.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "DEMO 1.2: Agent WITH Memory (InMemorySaver)\n",
      "======================================================================\n",
      "\n",
      "Now let's add a checkpointer to enable memory...\n",
      "\n",
      "âœ… Graph built WITH InMemorySaver (memory enabled!)\n",
      "\n",
      "Let's have the SAME conversation with memory...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# 1.2 SOLUTION: Agent WITH Memory (InMemorySaver)\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"DEMO 1.2: Agent WITH Memory (InMemorySaver)\")\n",
    "print(\"=\"*70)\n",
    "print(\"\\nNow let's add a checkpointer to enable memory...\\n\")\n",
    "\n",
    "# Build the SAME graph but WITH checkpointer\n",
    "builder = StateGraph(State)\n",
    "builder.add_node(\"chatbot\", chatbot_node)\n",
    "builder.add_edge(START, \"chatbot\")\n",
    "builder.add_edge(\"chatbot\", END)\n",
    "\n",
    "# Compile WITH InMemorySaver checkpointer\n",
    "checkpointer = InMemorySaver()\n",
    "graph_with_memory = builder.compile(checkpointer=checkpointer)\n",
    "\n",
    "print(\"âœ… Graph built WITH InMemorySaver (memory enabled!)\")\n",
    "print(\"\\nLet's have the SAME conversation with memory...\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------\n",
      "USER: My name is Ram and I'm a Data Engineer\n",
      "THREAD ID: 1\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "BOT: Nice to meet you, Ram! As a Data Engineer, I'm sure you're no stranger to working with large datasets, designing data pipelines, and building scalable data architectures. What kind of projects have you been working on lately? Are you more focused on cloud-based data engineering (e.g. AWS, GCP, Azure) or on-premises solutions?\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Configuration with thread_id\n",
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "\n",
    "# First message: Introduce yourself\n",
    "print(\"-\" * 70)\n",
    "print(\"USER: My name is Ram and I'm a Data Engineer\")\n",
    "print(f\"THREAD ID: {config['configurable']['thread_id']}\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "response1 = graph_with_memory.invoke({\n",
    "    \"messages\": [HumanMessage(content=\"My name is Ram and I'm a Data Engineer\")]\n",
    "}, config)\n",
    "\n",
    "print(f\"\\nBOT: {response1['messages'][-1].content}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------\n",
      "USER: What's my name?\n",
      "THREAD ID: 1\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "BOT: Your name is Ram!\n",
      "\n",
      "âœ… SUCCESS: The bot remembers your name!\n",
      "   The checkpointer stored the conversation history.\n"
     ]
    }
   ],
   "source": [
    "# Second message: Ask about the name (same thread)\n",
    "print(\"-\" * 70)\n",
    "print(\"USER: What's my name?\")\n",
    "print(f\"THREAD ID: {config['configurable']['thread_id']}\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "response2 = graph_with_memory.invoke({\n",
    "    \"messages\": [HumanMessage(content=\"What's my name?\")]\n",
    "}, config)\n",
    "\n",
    "print(f\"\\nBOT: {response2['messages'][-1].content}\\n\")\n",
    "\n",
    "print(\"âœ… SUCCESS: The bot remembers your name!\")\n",
    "print(\"   The checkpointer stored the conversation history.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------\n",
      "USER: What do I do for work?\n",
      "THREAD ID: 1\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "BOT: You're a Data Engineer!\n",
      "\n",
      "âœ… Bot remembers you're a Data Engineer!\n"
     ]
    }
   ],
   "source": [
    "# Third message: Ask about occupation\n",
    "print(\"-\" * 70)\n",
    "print(\"USER: What do I do for work?\")\n",
    "print(f\"THREAD ID: {config['configurable']['thread_id']}\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "response3 = graph_with_memory.invoke({\n",
    "    \"messages\": [HumanMessage(content=\"What do I do for work?\")]\n",
    "}, config)\n",
    "\n",
    "print(f\"\\nBOT: {response3['messages'][-1].content}\\n\")\n",
    "\n",
    "print(\"âœ… Bot remembers you're a Data Engineer!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "DEMO 1.4: Inspecting State and Checkpoints\n",
      "======================================================================\n",
      "\n",
      "Let's look at what's stored in the checkpoints...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# 1.4 INSPECT STATE: View Checkpoints\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"DEMO 1.4: Inspecting State and Checkpoints\")\n",
    "print(\"=\"*70)\n",
    "print(\"\\nLet's look at what's stored in the checkpoints...\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------\n",
      "CURRENT STATE - Thread 1\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Thread ID: 1\n",
      "Number of messages: 6\n",
      "\n",
      "Message History:\n",
      "\n",
      "1. USER: My name is Ram and I'm a Data Engineer...\n",
      "\n",
      "2. BOT: Nice to meet you, Ram! As a Data Engineer, I'm sure you're no stranger to working with large dataset...\n",
      "\n",
      "3. USER: What's my name?...\n",
      "\n",
      "4. BOT: Your name is Ram!...\n",
      "\n",
      "5. USER: What do I do for work?...\n",
      "\n",
      "6. BOT: You're a Data Engineer!...\n"
     ]
    }
   ],
   "source": [
    "# Get current state for Thread 1\n",
    "print(\"-\" * 70)\n",
    "print(\"CURRENT STATE - Thread 1\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "current_state = graph_with_memory.get_state(config)\n",
    "\n",
    "print(f\"\\nThread ID: {config['configurable']['thread_id']}\")\n",
    "print(f\"Number of messages: {len(current_state.values['messages'])}\")\n",
    "print(f\"\\nMessage History:\")\n",
    "\n",
    "for i, msg in enumerate(current_state.values['messages'], 1):\n",
    "    role = \"USER\" if isinstance(msg, HumanMessage) else \"BOT\"\n",
    "    print(f\"\\n{i}. {role}: {msg.content[:100]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------------------------------------\n",
      "CHECKPOINT HISTORY - Thread 1\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Total checkpoints: 9\n",
      "\n",
      "Checkpoint Timeline (most recent first):\n",
      "\n",
      "1. Checkpoint ID: 1f0b174e...\n",
      "   Messages in state: 6\n",
      "   Next nodes to execute: ()\n",
      "   Step: 7\n",
      "\n",
      "2. Checkpoint ID: 1f0b174e...\n",
      "   Messages in state: 5\n",
      "   Next nodes to execute: ('chatbot',)\n",
      "   Step: 6\n",
      "\n",
      "3. Checkpoint ID: 1f0b174e...\n",
      "   Messages in state: 4\n",
      "   Next nodes to execute: ('__start__',)\n",
      "   Step: 5\n",
      "\n",
      "4. Checkpoint ID: 1f0b174e...\n",
      "   Messages in state: 4\n",
      "   Next nodes to execute: ()\n",
      "   Step: 4\n",
      "\n",
      "5. Checkpoint ID: 1f0b174e...\n",
      "   Messages in state: 3\n",
      "   Next nodes to execute: ('chatbot',)\n",
      "   Step: 3\n"
     ]
    }
   ],
   "source": [
    "# View checkpoint history for Thread 1\n",
    "print(\"\\n\" + \"-\" * 70)\n",
    "print(\"CHECKPOINT HISTORY - Thread 1\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "history = list(graph_with_memory.get_state_history(config))\n",
    "\n",
    "print(f\"\\nTotal checkpoints: {len(history)}\")\n",
    "print(\"\\nCheckpoint Timeline (most recent first):\")\n",
    "\n",
    "for i, checkpoint in enumerate(history[:5], 1):  # Show first 5\n",
    "    print(f\"\\n{i}. Checkpoint ID: {checkpoint.config['configurable']['checkpoint_id'][:8]}...\")\n",
    "    print(f\"   Messages in state: {len(checkpoint.values.get('messages', []))}\")\n",
    "    print(f\"   Next nodes to execute: {checkpoint.next}\")\n",
    "    if checkpoint.metadata:\n",
    "        print(f\"   Step: {checkpoint.metadata.get('step', 'N/A')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# SECTION 2: LONG-TERM MEMORY (Cross-session Memory)\n",
    "# ============================================================================\n",
    "# \n",
    "# Long-term memory allows an agent to remember information ACROSS different\n",
    "# conversation threads/sessions. This is essential for:\n",
    "# - Remembering user preferences across multiple conversations\n",
    "# - Building persistent user profiles\n",
    "# - Sharing information across different chat sessions\n",
    "#\n",
    "# Key Concepts:\n",
    "# - Store: Key-value storage for persistent data\n",
    "# - Namespace: Organization structure (user_id, category)\n",
    "# - Cross-thread access: Same data available in any thread\n",
    "# ============================================================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "DEMO 2.1: The Limitation of Short-term Memory\n",
      "======================================================================\n",
      "\n",
      "Let's see what happens when we want to share info across threads...\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Thread A: Tell the bot your food preference\n",
      "THREAD ID: thread_a\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "USER: Remember this: I love butter chicken!\n",
      "BOT: I've taken note: You LOVE Butter Chicken! Would you like some recipe suggestions or restaurant recommendations?\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# 2.1 PROBLEM: Short-term Memory is Thread-scoped Only\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"DEMO 2.1: The Limitation of Short-term Memory\")\n",
    "print(\"=\"*70)\n",
    "print(\"\\nLet's see what happens when we want to share info across threads...\\n\")\n",
    "\n",
    "# Use the graph with memory from Section 1\n",
    "config_thread_a = {\"configurable\": {\"thread_id\": \"thread_a\"}}\n",
    "config_thread_b = {\"configurable\": {\"thread_id\": \"thread_b\"}}\n",
    "\n",
    "print(\"-\" * 70)\n",
    "print(\"Thread A: Tell the bot your food preference\")\n",
    "print(f\"THREAD ID: {config_thread_a['configurable']['thread_id']}\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "response_a = graph_with_memory.invoke({\n",
    "    \"messages\": [HumanMessage(content=\"Remember this: I love Butter chicken!\")]\n",
    "}, config_thread_a)\n",
    "\n",
    "print(f\"\\nUSER: Remember this: I love butter chicken!\")\n",
    "print(f\"BOT: {response_a['messages'][-1].content}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------\n",
      "Thread B: Ask about food preference (DIFFERENT THREAD)\n",
      "THREAD ID: thread_b\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "USER: What food do I love?\n",
      "BOT: Unfortunately, I'm a large language model, I don't have the ability to read your mind or know your personal preferences. However, I can try to help you figure out what food you might love.\n",
      "\n",
      "Can you give me some hints? Do you have a favorite cuisine, like Italian, Mexican, or Chinese? Or do you have a sweet tooth? Do you prefer savory, spicy, or comforting foods?\n",
      "\n",
      "âŒ PROBLEM: The bot doesn't remember!\n",
      "   Short-term memory (checkpointer) is THREAD-SCOPED.\n",
      "   Thread B cannot see Thread A's conversation.\n",
      "\n",
      "ðŸ’¡ SOLUTION: We need LONG-TERM MEMORY (Store)!\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# Now try to access that info from a different thread\n",
    "print(\"-\" * 70)\n",
    "print(\"Thread B: Ask about food preference (DIFFERENT THREAD)\")\n",
    "print(f\"THREAD ID: {config_thread_b['configurable']['thread_id']}\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "response_b = graph_with_memory.invoke({\n",
    "    \"messages\": [HumanMessage(content=\"What food do I love?\")]\n",
    "}, config_thread_b)\n",
    "\n",
    "print(f\"\\nUSER: What food do I love?\")\n",
    "print(f\"BOT: {response_b['messages'][-1].content}\\n\")\n",
    "\n",
    "print(\"âŒ PROBLEM: The bot doesn't remember!\")\n",
    "print(\"   Short-term memory (checkpointer) is THREAD-SCOPED.\")\n",
    "print(\"   Thread B cannot see Thread A's conversation.\\n\")\n",
    "\n",
    "print(\"ðŸ’¡ SOLUTION: We need LONG-TERM MEMORY (Store)!\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "DEMO 2.2: InMemoryStore - Long-term Memory\n",
      "======================================================================\n",
      "\n",
      "Let's introduce a Store for cross-thread memory...\n",
      "\n",
      "âœ… InMemoryStore created!\n",
      "\n",
      "A Store uses:\n",
      "  - Namespace: Tuple like ('user_123', 'preferences')\n",
      "  - Key: Unique identifier for each memory\n",
      "  - Value: Dictionary containing the data\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# 2.2 SOLUTION: InMemoryStore for Long-term Memory\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"DEMO 2.2: InMemoryStore - Long-term Memory\")\n",
    "print(\"=\"*70)\n",
    "print(\"\\nLet's introduce a Store for cross-thread memory...\\n\")\n",
    "\n",
    "# Create an InMemoryStore\n",
    "store = InMemoryStore()\n",
    "\n",
    "print(\"âœ… InMemoryStore created!\")\n",
    "print(\"\\nA Store uses:\")\n",
    "print(\"  - Namespace: Tuple like ('user_123', 'preferences')\")\n",
    "print(\"  - Key: Unique identifier for each memory\")\n",
    "print(\"  - Value: Dictionary containing the data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------------------------------------\n",
      "Manual Store Operations\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Namespace: ('user_ram', 'preferences')\n",
      "âœ… Stored: food preference = Butter chicken\n",
      "\n",
      "âœ… Retrieved: {'preference': 'Butter Chicken', 'notes': 'loves Butter chicken'}\n",
      "   Namespace: ('user_ram', 'preferences')\n",
      "   Key: food\n",
      "   Created at: 2025-10-25 07:33:25.650340+00:00\n"
     ]
    }
   ],
   "source": [
    "# Let's manually store and retrieve data\n",
    "print(\"\\n\" + \"-\" * 70)\n",
    "print(\"Manual Store Operations\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "# Define a namespace for user preferences\n",
    "user_id = \"user_ram\"\n",
    "namespace = (user_id, \"preferences\")\n",
    "\n",
    "print(f\"\\nNamespace: {namespace}\")\n",
    "\n",
    "# Store a preference\n",
    "store.put(\n",
    "    namespace=namespace,\n",
    "    key=\"food\",\n",
    "    value={\"preference\": \"Butter Chicken\", \"notes\": \"loves Butter chicken\"}\n",
    ")\n",
    "\n",
    "print(\"âœ… Stored: food preference = Butter chicken\")\n",
    "\n",
    "# Retrieve the preference\n",
    "item = store.get(namespace=namespace, key=\"food\")\n",
    "\n",
    "print(f\"\\nâœ… Retrieved: {item.value}\")\n",
    "print(f\"   Namespace: {item.namespace}\")\n",
    "print(f\"   Key: {item.key}\")\n",
    "print(f\"   Created at: {item.created_at}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------------------------------------\n",
      "Storing Multiple Preferences\n",
      "----------------------------------------------------------------------\n",
      "âœ… Stored: color = Black\n",
      "âœ… Stored: hobby = Soccer\n",
      "âœ… Stored: language = Python\n",
      "\n",
      "ðŸ“‚ All items in namespace ('user_ram', 'preferences'):\n",
      "  - food: Butter Chicken\n",
      "  - color: Black\n",
      "  - hobby: Soccer\n",
      "  - language: Python\n"
     ]
    }
   ],
   "source": [
    "# Store multiple items\n",
    "print(\"\\n\" + \"-\" * 70)\n",
    "print(\"Storing Multiple Preferences\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "store.put(namespace, \"color\", {\"preference\": \"Black\"})\n",
    "store.put(namespace, \"hobby\", {\"preference\": \"Soccer\"})\n",
    "store.put(namespace, \"language\", {\"preference\": \"Python\"})\n",
    "\n",
    "print(\"âœ… Stored: color = Black\")\n",
    "print(\"âœ… Stored: hobby = Soccer\")\n",
    "print(\"âœ… Stored: language = Python\")\n",
    "\n",
    "# Search/list all items in namespace\n",
    "print(f\"\\nðŸ“‚ All items in namespace {namespace}:\")\n",
    "\n",
    "items = store.search(namespace)\n",
    "for item in items:\n",
    "    print(f\"  - {item.key}: {item.value['preference']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "DEMO 2.3: Agent with BOTH Checkpointer AND Store\n",
      "======================================================================\n",
      "\n",
      "Now let's build an agent that uses both memory types...\n",
      "\n",
      "âœ… Graph compiled with:\n",
      "   - Checkpointer (short-term memory)\n",
      "   - Store (long-term memory)\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# 2.3 AGENT WITH STORE: Combining Short-term and Long-term Memory\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"DEMO 2.3: Agent with BOTH Checkpointer AND Store\")\n",
    "print(\"=\"*70)\n",
    "print(\"\\nNow let's build an agent that uses both memory types...\\n\")\n",
    "\n",
    "# Define agent that reads from store before responding\n",
    "def chatbot_with_memory(state: MessagesState, config: RunnableConfig, store: BaseStore) -> dict:\n",
    "    \"\"\"\n",
    "    Chatbot that:\n",
    "    1. Reads user preferences from store (long-term memory)\n",
    "    2. Uses conversation history from checkpointer (short-term memory)\n",
    "    3. Responds with context from both\n",
    "    \"\"\"\n",
    "    # Get user_id from config\n",
    "    user_id = config.get(\"configurable\", {}).get(\"user_id\", \"unknown_user\")\n",
    "    namespace = (user_id, \"preferences\")\n",
    "    \n",
    "    # Search for user preferences in store\n",
    "    preferences_items = store.search(namespace)\n",
    "    \n",
    "    # Build context from stored preferences\n",
    "    if preferences_items:\n",
    "        prefs = []\n",
    "        for item in preferences_items:\n",
    "            prefs.append(f\"{item.key}: {item.value.get('preference', 'N/A')}\")\n",
    "        preferences_text = \"User preferences: \" + \", \".join(prefs)\n",
    "    else:\n",
    "        preferences_text = \"No user preferences stored yet.\"\n",
    "    \n",
    "    # Get conversation messages (from checkpointer)\n",
    "    messages = state[\"messages\"]\n",
    "    \n",
    "    # Add system message with preferences context\n",
    "    system_message = HumanMessage(content=f\"[System Context: {preferences_text}]\")\n",
    "    \n",
    "    # Call LLM with both contexts\n",
    "    full_messages = [system_message] + messages\n",
    "    response = llm.invoke(full_messages)\n",
    "    \n",
    "    # Check if user is sharing a preference to store\n",
    "    last_user_message = messages[-1].content.lower() if messages else \"\"\n",
    "    \n",
    "    if \"remember\" in last_user_message or \"i love\" in last_user_message or \"i like\" in last_user_message:\n",
    "        # Simple extraction (in production, use LLM to extract structured data)\n",
    "        if \"butter chicken\" in last_user_message:\n",
    "            store.put(namespace, \"food\", {\"preference\": \"butter chicken\"})\n",
    "            print(f\"   ðŸ’¾ Stored preference: food = butter chicken\")\n",
    "        elif \"blue\" in last_user_message:\n",
    "            store.put(namespace, \"color\", {\"preference\": \"black\"})\n",
    "            print(f\"   ðŸ’¾ Stored preference: color = black\")\n",
    "    \n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "# Build graph with BOTH checkpointer and store\n",
    "builder_with_store = StateGraph(MessagesState)\n",
    "builder_with_store.add_node(\"chatbot\", chatbot_with_memory)\n",
    "builder_with_store.add_edge(START, \"chatbot\")\n",
    "builder_with_store.add_edge(\"chatbot\", END)\n",
    "\n",
    "# Compile with BOTH memory systems\n",
    "checkpointer = InMemorySaver()\n",
    "store = InMemoryStore()\n",
    "\n",
    "graph_full_memory = builder_with_store.compile(\n",
    "    checkpointer=checkpointer,\n",
    "    store=store\n",
    ")\n",
    "\n",
    "print(\"âœ… Graph compiled with:\")\n",
    "print(\"   - Checkpointer (short-term memory)\")\n",
    "print(\"   - Store (long-term memory)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "DEMO 2.4: Cross-thread Memory in Action\n",
      "======================================================================\n",
      "\n",
      "Let's see long-term memory work across different threads...\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "SESSION 1: Store preferences\n",
      "Thread ID: session_1\n",
      "User ID: user_ram\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "USER: Remember this: I love butter chicken!\n",
      "   ðŸ’¾ Stored preference: food = butter chicken\n",
      "BOT: I've taken note of that! You love butter chicken. I'll keep that in mind for our conversation. Would you like some recommendations or recipes for butter chicken, or is there something else I can help you with?\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# 2.4 CROSS-THREAD MEMORY: Using Long-term Memory Across Sessions\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"DEMO 2.4: Cross-thread Memory in Action\")\n",
    "print(\"=\"*70)\n",
    "print(\"\\nLet's see long-term memory work across different threads...\\n\")\n",
    "\n",
    "# Configuration for Thread 1 with user_id\n",
    "config_session1 = {\n",
    "    \"configurable\": {\n",
    "        \"thread_id\": \"session_1\",\n",
    "        \"user_id\": \"user_ram\"\n",
    "    }\n",
    "}\n",
    "\n",
    "print(\"-\" * 70)\n",
    "print(\"SESSION 1: Store preferences\")\n",
    "print(f\"Thread ID: {config_session1['configurable']['thread_id']}\")\n",
    "print(f\"User ID: {config_session1['configurable']['user_id']}\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "print(\"\\nUSER: Remember this: I love butter chicken!\")\n",
    "\n",
    "response1 = graph_full_memory.invoke({\n",
    "    \"messages\": [HumanMessage(content=\"Remember this: I love butter chicken!\")]\n",
    "}, config_session1)\n",
    "\n",
    "print(f\"BOT: {response1['messages'][-1].content}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------\n",
      "SESSION 2: Different thread, same user\n",
      "Thread ID: session_2\n",
      "User ID: user_ram\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "USER: What food do I love?\n",
      "BOT: You love Butter Chicken!\n",
      "\n",
      "âœ… SUCCESS: Bot remembers across threads!\n",
      "   Long-term memory (store) is shared across all threads for same user.\n"
     ]
    }
   ],
   "source": [
    "# Now start a DIFFERENT thread but SAME user_id\n",
    "config_session2 = {\n",
    "    \"configurable\": {\n",
    "        \"thread_id\": \"session_2\",  # Different thread!\n",
    "        \"user_id\": \"user_ram\"      # Same user!\n",
    "    }\n",
    "}\n",
    "\n",
    "print(\"-\" * 70)\n",
    "print(\"SESSION 2: Different thread, same user\")\n",
    "print(f\"Thread ID: {config_session2['configurable']['thread_id']}\")\n",
    "print(f\"User ID: {config_session2['configurable']['user_id']}\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "print(\"\\nUSER: What food do I love?\")\n",
    "\n",
    "response2 = graph_full_memory.invoke({\n",
    "    \"messages\": [HumanMessage(content=\"What food do I love?\")]\n",
    "}, config_session2)\n",
    "\n",
    "print(f\"BOT: {response2['messages'][-1].content}\\n\")\n",
    "\n",
    "print(\"âœ… SUCCESS: Bot remembers across threads!\")\n",
    "print(\"   Long-term memory (store) is shared across all threads for same user.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "DEMO 2.5: Multiple Namespaces for Organization\n",
      "======================================================================\n",
      "\n",
      "Stores can organize memory into different namespaces...\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Storing data in different namespaces\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "âœ… Profile namespace: ('user_ram', 'profile')\n",
      "   - name: Ram\n",
      "   - occupation: Data Engineer\n",
      "   - location: Boston\n",
      "\n",
      "âœ… Preferences namespace: ('user_ram', 'preferences')\n",
      "   - food: butter chicken\n",
      "   - color: blue\n",
      "   - language: Python\n",
      "\n",
      "âœ… Notes namespace: ('user_ram', 'notes')\n",
      "   - note_1: Interested in AI/ML\n",
      "   - note_2: Working on LangGraph lab\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# 2.5 MULTIPLE NAMESPACES: Organizing Different Types of Memory\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"DEMO 2.5: Multiple Namespaces for Organization\")\n",
    "print(\"=\"*70)\n",
    "print(\"\\nStores can organize memory into different namespaces...\\n\")\n",
    "\n",
    "user_id = \"user_ram\"\n",
    "\n",
    "# Different namespace categories\n",
    "namespace_profile = (user_id, \"profile\")\n",
    "namespace_preferences = (user_id, \"preferences\")\n",
    "namespace_notes = (user_id, \"notes\")\n",
    "\n",
    "print(\"-\" * 70)\n",
    "print(\"Storing data in different namespaces\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "# Profile information\n",
    "store.put(namespace_profile, \"name\", {\"value\": \"Ram\"})\n",
    "store.put(namespace_profile, \"occupation\", {\"value\": \"Data Engineer\"})\n",
    "store.put(namespace_profile, \"location\", {\"value\": \"Boston\"})\n",
    "\n",
    "print(f\"\\nâœ… Profile namespace: {namespace_profile}\")\n",
    "print(\"   - name: Ram\")\n",
    "print(\"   - occupation: Data Engineer\")\n",
    "print(\"   - location: Boston\")\n",
    "\n",
    "# Preferences\n",
    "store.put(namespace_preferences, \"food\", {\"value\": \"butter chicken\"})\n",
    "store.put(namespace_preferences, \"color\", {\"value\": \"blue\"})\n",
    "store.put(namespace_preferences, \"language\", {\"value\": \"Python\"})\n",
    "\n",
    "print(f\"\\nâœ… Preferences namespace: {namespace_preferences}\")\n",
    "print(\"   - food: butter chicken\")\n",
    "print(\"   - color: blue\")\n",
    "print(\"   - language: Python\")\n",
    "\n",
    "# Notes\n",
    "store.put(namespace_notes, \"note_1\", {\"content\": \"Interested in AI/ML\"})\n",
    "store.put(namespace_notes, \"note_2\", {\"content\": \"Working on LangGraph lab\"})\n",
    "\n",
    "print(f\"\\nâœ… Notes namespace: {namespace_notes}\")\n",
    "print(\"   - note_1: Interested in AI/ML\")\n",
    "print(\"   - note_2: Working on LangGraph lab\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------------------------------------\n",
      "Retrieving from specific namespaces\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "ðŸ“‚ Profile (('user_ram', 'profile')):\n",
      "   name: Ram\n",
      "   occupation: Data Engineer\n",
      "   location: Boston\n",
      "\n",
      "ðŸ“‚ Preferences (('user_ram', 'preferences')):\n",
      "   food: butter chicken\n",
      "   color: blue\n",
      "   language: Python\n",
      "\n",
      "ðŸ“‚ Notes (('user_ram', 'notes')):\n",
      "   note_1: Interested in AI/ML\n",
      "   note_2: Working on LangGraph lab\n"
     ]
    }
   ],
   "source": [
    "# Retrieve from specific namespaces\n",
    "print(\"\\n\" + \"-\" * 70)\n",
    "print(\"Retrieving from specific namespaces\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "# Get all profile items\n",
    "profile_items = store.search(namespace_profile)\n",
    "print(f\"\\nðŸ“‚ Profile ({namespace_profile}):\")\n",
    "for item in profile_items:\n",
    "    print(f\"   {item.key}: {item.value['value']}\")\n",
    "\n",
    "# Get all preference items\n",
    "pref_items = store.search(namespace_preferences)\n",
    "print(f\"\\nðŸ“‚ Preferences ({namespace_preferences}):\")\n",
    "for item in pref_items:\n",
    "    print(f\"   {item.key}: {item.value['value']}\")\n",
    "\n",
    "# Get all notes\n",
    "note_items = store.search(namespace_notes)\n",
    "print(f\"\\nðŸ“‚ Notes ({namespace_notes}):\")\n",
    "for item in note_items:\n",
    "    print(f\"   {item.key}: {item.value['content']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# SECTION 3: SNOWFLAKE-BACKED MEMORY (Production Setup)\n",
    "# ============================================================================\n",
    "# \n",
    "# In production, we need persistent storage that survives:\n",
    "# - Application restarts\n",
    "# - Server failures\n",
    "# - Notebook kernel restarts\n",
    "#\n",
    "# Snowflake provides:\n",
    "# - Reliable, scalable database storage\n",
    "# - SQL access for debugging and monitoring\n",
    "# - Integration with entire data platform\n",
    "#\n",
    "# We'll implement:\n",
    "# 1. SnowflakeCheckpointer - for short-term memory (conversation history)\n",
    "# 2. SnowflakeStore - for long-term memory (user profiles, preferences)\n",
    "# ============================================================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "STEP 3.1: Creating Snowflake Tables for Memory Storage\n",
      "======================================================================\n",
      "\n",
      "We need two tables:\n",
      "  1. CHECKPOINTS - for conversation history (short-term)\n",
      "  2. MEMORY_STORE - for persistent data (long-term)\n",
      "\n",
      "Creating CHECKPOINTS table...\n",
      "----------------------------------------------------------------------\n",
      "âœ… CHECKPOINTS table created successfully!\n",
      "\n",
      "Creating MEMORY_STORE table...\n",
      "----------------------------------------------------------------------\n",
      "âœ… MEMORY_STORE table created successfully!\n",
      "\n",
      "Verifying tables...\n",
      "----------------------------------------------------------------------\n",
      "âœ… CHECKPOINTS table exists\n",
      "âœ… MEMORY_STORE table exists\n",
      "\n",
      "âœ… All tables created and verified!\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# 3.1 CREATE SNOWFLAKE TABLES\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"STEP 3.1: Creating Snowflake Tables for Memory Storage\")\n",
    "print(\"=\"*70)\n",
    "print(\"\\nWe need two tables:\")\n",
    "print(\"  1. CHECKPOINTS - for conversation history (short-term)\")\n",
    "print(\"  2. MEMORY_STORE - for persistent data (long-term)\")\n",
    "print()\n",
    "\n",
    "\n",
    "# SQL to create CHECKPOINTS table\n",
    "create_checkpoints_table = \"\"\"\n",
    "CREATE TABLE IF NOT EXISTS CHECKPOINTS (\n",
    "    thread_id VARCHAR(500) NOT NULL,\n",
    "    checkpoint_id VARCHAR(500) NOT NULL,\n",
    "    parent_checkpoint_id VARCHAR(500),\n",
    "    checkpoint_data VARIANT,\n",
    "    metadata VARIANT,\n",
    "    created_at TIMESTAMP_NTZ DEFAULT CURRENT_TIMESTAMP(),\n",
    "    PRIMARY KEY (thread_id, checkpoint_id)\n",
    ");\n",
    "\"\"\"\n",
    "\n",
    "print(\"Creating CHECKPOINTS table...\")\n",
    "print(\"-\" * 70)\n",
    "try:\n",
    "    execute_snowflake_query(create_checkpoints_table, fetch=False)\n",
    "    print(\"âœ… CHECKPOINTS table created successfully!\\n\")\n",
    "except Exception as e:\n",
    "    print(f\"âŒ Error creating CHECKPOINTS table: {e}\\n\")\n",
    "\n",
    "# SQL to create MEMORY_STORE table\n",
    "create_memory_store_table = \"\"\"\n",
    "CREATE TABLE IF NOT EXISTS MEMORY_STORE (\n",
    "    namespace VARCHAR(1000) NOT NULL,\n",
    "    key VARCHAR(500) NOT NULL,\n",
    "    value VARIANT,\n",
    "    created_at TIMESTAMP_NTZ DEFAULT CURRENT_TIMESTAMP(),\n",
    "    updated_at TIMESTAMP_NTZ DEFAULT CURRENT_TIMESTAMP(),\n",
    "    PRIMARY KEY (namespace, key)\n",
    ");\n",
    "\"\"\"\n",
    "\n",
    "print(\"Creating MEMORY_STORE table...\")\n",
    "print(\"-\" * 70)\n",
    "try:\n",
    "    execute_snowflake_query(create_memory_store_table, fetch=False)\n",
    "    print(\"âœ… MEMORY_STORE table created successfully!\\n\")\n",
    "except Exception as e:\n",
    "    print(f\"âŒ Error creating MEMORY_STORE table: {e}\\n\")\n",
    "\n",
    "# Verify tables were created\n",
    "print(\"Verifying tables...\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "verify_query = \"SHOW TABLES LIKE 'CHECKPOINTS';\"\n",
    "result = execute_snowflake_query(verify_query)\n",
    "if result:\n",
    "    print(\"âœ… CHECKPOINTS table exists\")\n",
    "\n",
    "verify_query = \"SHOW TABLES LIKE 'MEMORY_STORE';\"\n",
    "result = execute_snowflake_query(verify_query)\n",
    "if result:\n",
    "    print(\"âœ… MEMORY_STORE table exists\")\n",
    "\n",
    "print(\"\\nâœ… All tables created and verified!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "STEP 3.2: Defining Serialization Helpers\n",
      "======================================================================\n",
      "âœ… Serialization helpers defined!\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# 3.2 SERIALIZATION HELPERS\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"STEP 3.2: Defining Serialization Helpers\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "from typing import Optional, Iterator, Sequence\n",
    "\n",
    "def serialize_checkpoint(checkpoint: dict) -> str:\n",
    "    \"\"\"\n",
    "    Serialize checkpoint data, handling LangChain message objects.\n",
    "    \"\"\"\n",
    "    def convert_messages(obj):\n",
    "        if isinstance(obj, (HumanMessage, AIMessage, SystemMessage)):\n",
    "            return {\n",
    "                \"type\": obj.__class__.__name__,\n",
    "                \"content\": obj.content,\n",
    "                \"id\": getattr(obj, \"id\", None)\n",
    "            }\n",
    "        elif isinstance(obj, dict):\n",
    "            return {k: convert_messages(v) for k, v in obj.items()}\n",
    "        elif isinstance(obj, list):\n",
    "            return [convert_messages(item) for item in obj]\n",
    "        else:\n",
    "            return obj\n",
    "    \n",
    "    serializable_checkpoint = convert_messages(checkpoint)\n",
    "    return json.dumps(serializable_checkpoint)\n",
    "\n",
    "\n",
    "def deserialize_checkpoint(checkpoint_data) -> dict:\n",
    "    \"\"\"\n",
    "    Deserialize checkpoint data, converting dicts back to message objects.\n",
    "    \"\"\"\n",
    "    def convert_to_messages(obj):\n",
    "        if isinstance(obj, dict):\n",
    "            if \"type\" in obj and obj[\"type\"] in [\"HumanMessage\", \"AIMessage\", \"SystemMessage\"]:\n",
    "                msg_type = obj[\"type\"]\n",
    "                content = obj.get(\"content\", \"\")\n",
    "                \n",
    "                if msg_type == \"HumanMessage\":\n",
    "                    return HumanMessage(content=content)\n",
    "                elif msg_type == \"AIMessage\":\n",
    "                    return AIMessage(content=content)\n",
    "                elif msg_type == \"SystemMessage\":\n",
    "                    return SystemMessage(content=content)\n",
    "            else:\n",
    "                return {k: convert_to_messages(v) for k, v in obj.items()}\n",
    "        elif isinstance(obj, list):\n",
    "            return [convert_to_messages(item) for item in obj]\n",
    "        else:\n",
    "            return obj\n",
    "    \n",
    "    if isinstance(checkpoint_data, str):\n",
    "        checkpoint_dict = json.loads(checkpoint_data)\n",
    "    else:\n",
    "        checkpoint_dict = checkpoint_data\n",
    "    \n",
    "    return convert_to_messages(checkpoint_dict)\n",
    "\n",
    "print(\"âœ… Serialization helpers defined!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "STEP 3.3: Building SnowflakeCheckpointer\n",
      "======================================================================\n",
      "âœ… SnowflakeCheckpointer class implemented!\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# 3.3 SNOWFLAKE CHECKPOINTER (With Proper VARIANT Casting)\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"STEP 3.3: Building SnowflakeCheckpointer\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "class SnowflakeCheckpointer(BaseCheckpointSaver):\n",
    "    \"\"\"\n",
    "    Checkpointer that stores conversation state in Snowflake.\n",
    "    Uses PARSE_JSON to properly cast strings to VARIANT.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.connection = None\n",
    "    \n",
    "    def _get_connection(self):\n",
    "        if self.connection is None or self.connection.is_closed():\n",
    "            self.connection = get_snowflake_connection()\n",
    "        return self.connection\n",
    "    \n",
    "    def put(self, config: RunnableConfig, checkpoint: dict, metadata: dict, new_versions: dict) -> RunnableConfig:\n",
    "        \"\"\"Save a checkpoint to Snowflake with proper VARIANT casting.\"\"\"\n",
    "        thread_id = config.get(\"configurable\", {}).get(\"thread_id\")\n",
    "        if not thread_id:\n",
    "            raise ValueError(\"thread_id is required in config\")\n",
    "        \n",
    "        checkpoint_id = str(uuid.uuid4())\n",
    "        parent_checkpoint_id = config.get(\"configurable\", {}).get(\"checkpoint_id\")\n",
    "        \n",
    "        # Serialize to JSON strings\n",
    "        checkpoint_json_str = serialize_checkpoint(checkpoint)\n",
    "        metadata_json_str = json.dumps(metadata)\n",
    "        \n",
    "        # Use PARSE_JSON in the query to cast string to VARIANT\n",
    "        insert_query = \"\"\"\n",
    "        INSERT INTO CHECKPOINTS (thread_id, checkpoint_id, parent_checkpoint_id, checkpoint_data, metadata)\n",
    "        SELECT %s, %s, %s, PARSE_JSON(%s), PARSE_JSON(%s)\n",
    "        \"\"\"\n",
    "        \n",
    "        conn = self._get_connection()\n",
    "        cursor = conn.cursor()\n",
    "        \n",
    "        try:\n",
    "            cursor.execute(\n",
    "                insert_query,\n",
    "                (thread_id, checkpoint_id, parent_checkpoint_id, checkpoint_json_str, metadata_json_str)\n",
    "            )\n",
    "            conn.commit()\n",
    "            cursor.close()\n",
    "        except Exception as e:\n",
    "            cursor.close()\n",
    "            print(f\"Error in put: {e}\")\n",
    "            raise e\n",
    "        \n",
    "        return {\"configurable\": {\"thread_id\": thread_id, \"checkpoint_id\": checkpoint_id}}\n",
    "    \n",
    "    def put_writes(self, config: RunnableConfig, writes: Sequence[tuple], task_id: str) -> None:\n",
    "        pass\n",
    "    \n",
    "    def get_tuple(self, config: RunnableConfig) -> Optional[CheckpointTuple]:\n",
    "        \"\"\"Retrieve a checkpoint from Snowflake.\"\"\"\n",
    "        thread_id = config.get(\"configurable\", {}).get(\"thread_id\")\n",
    "        checkpoint_id = config.get(\"configurable\", {}).get(\"checkpoint_id\")\n",
    "        \n",
    "        if not thread_id:\n",
    "            return None\n",
    "        \n",
    "        conn = self._get_connection()\n",
    "        cursor = conn.cursor(DictCursor)\n",
    "        \n",
    "        try:\n",
    "            if checkpoint_id:\n",
    "                query = \"\"\"\n",
    "                SELECT checkpoint_id, parent_checkpoint_id, checkpoint_data, metadata, created_at\n",
    "                FROM CHECKPOINTS WHERE thread_id = %s AND checkpoint_id = %s\n",
    "                \"\"\"\n",
    "                cursor.execute(query, (thread_id, checkpoint_id))\n",
    "            else:\n",
    "                query = \"\"\"\n",
    "                SELECT checkpoint_id, parent_checkpoint_id, checkpoint_data, metadata, created_at\n",
    "                FROM CHECKPOINTS WHERE thread_id = %s ORDER BY created_at DESC LIMIT 1\n",
    "                \"\"\"\n",
    "                cursor.execute(query, (thread_id,))\n",
    "            \n",
    "            result = cursor.fetchone()\n",
    "            cursor.close()\n",
    "            \n",
    "            if not result:\n",
    "                return None\n",
    "            \n",
    "            # Snowflake returns VARIANT as dict/list automatically\n",
    "            checkpoint_data = result['CHECKPOINT_DATA']\n",
    "            checkpoint = deserialize_checkpoint(checkpoint_data)\n",
    "            \n",
    "            metadata_data = result['METADATA']\n",
    "            if isinstance(metadata_data, str):\n",
    "                metadata = json.loads(metadata_data)\n",
    "            else:\n",
    "                metadata = metadata_data if metadata_data else {}\n",
    "            \n",
    "            return CheckpointTuple(\n",
    "                config={\"configurable\": {\"thread_id\": thread_id, \"checkpoint_id\": result['CHECKPOINT_ID']}},\n",
    "                checkpoint=checkpoint,\n",
    "                metadata=metadata,\n",
    "                parent_config={\"configurable\": {\"thread_id\": thread_id, \"checkpoint_id\": result['PARENT_CHECKPOINT_ID']}} if result['PARENT_CHECKPOINT_ID'] else None,\n",
    "                pending_writes=[]\n",
    "            )\n",
    "        \n",
    "        except Exception as e:\n",
    "            cursor.close()\n",
    "            print(f\"Error in get_tuple: {e}\")\n",
    "            raise e\n",
    "    \n",
    "    def list(self, config: RunnableConfig, *, filter: Optional[dict] = None, before: Optional[RunnableConfig] = None, limit: Optional[int] = None) -> Iterator[CheckpointTuple]:\n",
    "        \"\"\"List all checkpoints for a thread.\"\"\"\n",
    "        thread_id = config.get(\"configurable\", {}).get(\"thread_id\")\n",
    "        if not thread_id:\n",
    "            return\n",
    "        \n",
    "        conn = self._get_connection()\n",
    "        cursor = conn.cursor(DictCursor)\n",
    "        \n",
    "        try:\n",
    "            query = \"\"\"\n",
    "            SELECT checkpoint_id, parent_checkpoint_id, checkpoint_data, metadata, created_at\n",
    "            FROM CHECKPOINTS WHERE thread_id = %s ORDER BY created_at DESC\n",
    "            \"\"\"\n",
    "            if limit:\n",
    "                query += f\" LIMIT {limit}\"\n",
    "            \n",
    "            cursor.execute(query, (thread_id,))\n",
    "            results = cursor.fetchall()\n",
    "            cursor.close()\n",
    "            \n",
    "            for result in results:\n",
    "                checkpoint_data = result['CHECKPOINT_DATA']\n",
    "                checkpoint = deserialize_checkpoint(checkpoint_data)\n",
    "                \n",
    "                metadata_data = result['METADATA']\n",
    "                if isinstance(metadata_data, str):\n",
    "                    metadata = json.loads(metadata_data)\n",
    "                else:\n",
    "                    metadata = metadata_data if metadata_data else {}\n",
    "                \n",
    "                yield CheckpointTuple(\n",
    "                    config={\"configurable\": {\"thread_id\": thread_id, \"checkpoint_id\": result['CHECKPOINT_ID']}},\n",
    "                    checkpoint=checkpoint,\n",
    "                    metadata=metadata,\n",
    "                    parent_config={\"configurable\": {\"thread_id\": thread_id, \"checkpoint_id\": result['PARENT_CHECKPOINT_ID']}} if result['PARENT_CHECKPOINT_ID'] else None,\n",
    "                    pending_writes=[]\n",
    "                )\n",
    "        \n",
    "        except Exception as e:\n",
    "            cursor.close()\n",
    "            raise e\n",
    "    \n",
    "    async def aget_tuple(self, config: RunnableConfig) -> Optional[CheckpointTuple]:\n",
    "        return self.get_tuple(config)\n",
    "    \n",
    "    async def alist(self, config: RunnableConfig, *, filter: Optional[dict] = None, before: Optional[RunnableConfig] = None, limit: Optional[int] = None) -> Iterator[CheckpointTuple]:\n",
    "        for item in self.list(config, filter=filter, before=before, limit=limit):\n",
    "            yield item\n",
    "    \n",
    "    async def aput(self, config: RunnableConfig, checkpoint: dict, metadata: dict, new_versions: dict) -> RunnableConfig:\n",
    "        return self.put(config, checkpoint, metadata, new_versions)\n",
    "    \n",
    "    async def aput_writes(self, config: RunnableConfig, writes: Sequence[tuple], task_id: str) -> None:\n",
    "        return self.put_writes(config, writes, task_id)\n",
    "    \n",
    "    def __del__(self):\n",
    "        if self.connection and not self.connection.is_closed():\n",
    "            self.connection.close()\n",
    "\n",
    "print(\"âœ… SnowflakeCheckpointer class implemented!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "STEP 3.4: Building SnowflakeStore\n",
      "======================================================================\n",
      "âœ… SnowflakeStore class implemented!\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# 3.4 SNOWFLAKE STORE (With Proper VARIANT Casting)\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"STEP 3.4: Building SnowflakeStore\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "class SnowflakeStore(BaseStore):\n",
    "    \"\"\"\n",
    "    Store that persists long-term memory in Snowflake.\n",
    "    Uses PARSE_JSON to properly cast strings to VARIANT.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.connection = None\n",
    "    \n",
    "    def _get_connection(self):\n",
    "        if self.connection is None or self.connection.is_closed():\n",
    "            self.connection = get_snowflake_connection()\n",
    "        return self.connection\n",
    "    \n",
    "    def _namespace_to_string(self, namespace: Tuple[str, ...]) -> str:\n",
    "        return json.dumps(namespace)\n",
    "    \n",
    "    def _string_to_namespace(self, namespace_str: str) -> Tuple[str, ...]:\n",
    "        return tuple(json.loads(namespace_str))\n",
    "    \n",
    "    def put(self, namespace: Tuple[str, ...], key: str, value: dict) -> None:\n",
    "        \"\"\"Store a value with proper VARIANT casting.\"\"\"\n",
    "        namespace_str = self._namespace_to_string(namespace)\n",
    "        value_json_str = json.dumps(value)\n",
    "        \n",
    "        # Use PARSE_JSON with SELECT to cast string to VARIANT\n",
    "        merge_query = \"\"\"\n",
    "        MERGE INTO MEMORY_STORE AS target\n",
    "        USING (SELECT %s AS namespace, %s AS key, PARSE_JSON(%s) AS value) AS source\n",
    "        ON target.namespace = source.namespace AND target.key = source.key\n",
    "        WHEN MATCHED THEN\n",
    "            UPDATE SET value = source.value, updated_at = CURRENT_TIMESTAMP()\n",
    "        WHEN NOT MATCHED THEN\n",
    "            INSERT (namespace, key, value, created_at, updated_at)\n",
    "            VALUES (source.namespace, source.key, source.value, CURRENT_TIMESTAMP(), CURRENT_TIMESTAMP())\n",
    "        \"\"\"\n",
    "        \n",
    "        conn = self._get_connection()\n",
    "        cursor = conn.cursor()\n",
    "        \n",
    "        try:\n",
    "            cursor.execute(merge_query, (namespace_str, key, value_json_str))\n",
    "            conn.commit()\n",
    "            cursor.close()\n",
    "        except Exception as e:\n",
    "            cursor.close()\n",
    "            print(f\"Error in put: {e}\")\n",
    "            raise e\n",
    "    \n",
    "    def get(self, namespace: Tuple[str, ...], key: str) -> Optional[Item]:\n",
    "        \"\"\"Retrieve a value from Snowflake.\"\"\"\n",
    "        namespace_str = self._namespace_to_string(namespace)\n",
    "        \n",
    "        query = \"\"\"\n",
    "        SELECT namespace, key, value, created_at, updated_at\n",
    "        FROM MEMORY_STORE WHERE namespace = %s AND key = %s\n",
    "        \"\"\"\n",
    "        \n",
    "        conn = self._get_connection()\n",
    "        cursor = conn.cursor(DictCursor)\n",
    "        \n",
    "        try:\n",
    "            cursor.execute(query, (namespace_str, key))\n",
    "            result = cursor.fetchone()\n",
    "            cursor.close()\n",
    "            \n",
    "            if not result:\n",
    "                return None\n",
    "            \n",
    "            # Snowflake returns VARIANT as dict automatically\n",
    "            value = result['VALUE']\n",
    "            \n",
    "            return Item(\n",
    "                namespace=self._string_to_namespace(result['NAMESPACE']),\n",
    "                key=result['KEY'],\n",
    "                value=value,\n",
    "                created_at=result['CREATED_AT'].isoformat() if result['CREATED_AT'] else None,\n",
    "                updated_at=result['UPDATED_AT'].isoformat() if result['UPDATED_AT'] else None\n",
    "            )\n",
    "        \n",
    "        except Exception as e:\n",
    "            cursor.close()\n",
    "            raise e\n",
    "    \n",
    "    def search(self, namespace: Tuple[str, ...]) -> List[Item]:\n",
    "        \"\"\"Search for all items in a namespace.\"\"\"\n",
    "        namespace_str = self._namespace_to_string(namespace)\n",
    "        \n",
    "        query = \"\"\"\n",
    "        SELECT namespace, key, value, created_at, updated_at\n",
    "        FROM MEMORY_STORE WHERE namespace = %s ORDER BY created_at DESC\n",
    "        \"\"\"\n",
    "        \n",
    "        conn = self._get_connection()\n",
    "        cursor = conn.cursor(DictCursor)\n",
    "        \n",
    "        try:\n",
    "            cursor.execute(query, (namespace_str,))\n",
    "            results = cursor.fetchall()\n",
    "            cursor.close()\n",
    "            \n",
    "            items = []\n",
    "            for result in results:\n",
    "                items.append(Item(\n",
    "                    namespace=self._string_to_namespace(result['NAMESPACE']),\n",
    "                    key=result['KEY'],\n",
    "                    value=result['VALUE'],\n",
    "                    created_at=result['CREATED_AT'].isoformat() if result['CREATED_AT'] else None,\n",
    "                    updated_at=result['UPDATED_AT'].isoformat() if result['UPDATED_AT'] else None\n",
    "                ))\n",
    "            \n",
    "            return items\n",
    "        \n",
    "        except Exception as e:\n",
    "            cursor.close()\n",
    "            raise e\n",
    "    \n",
    "    def delete(self, namespace: Tuple[str, ...], key: str) -> None:\n",
    "        namespace_str = self._namespace_to_string(namespace)\n",
    "        delete_query = \"DELETE FROM MEMORY_STORE WHERE namespace = %s AND key = %s\"\n",
    "        \n",
    "        conn = self._get_connection()\n",
    "        cursor = conn.cursor()\n",
    "        cursor.execute(delete_query, (namespace_str, key))\n",
    "        conn.commit()\n",
    "        cursor.close()\n",
    "    \n",
    "    def batch(self, operations: List[tuple]) -> List[Any]:\n",
    "        results = []\n",
    "        for op in operations:\n",
    "            op_type = op[0]\n",
    "            if op_type == \"put\":\n",
    "                _, namespace, key, value = op\n",
    "                self.put(namespace, key, value)\n",
    "                results.append(None)\n",
    "            elif op_type == \"get\":\n",
    "                _, namespace, key = op\n",
    "                result = self.get(namespace, key)\n",
    "                results.append(result)\n",
    "            elif op_type == \"delete\":\n",
    "                _, namespace, key = op\n",
    "                self.delete(namespace, key)\n",
    "                results.append(None)\n",
    "        return results\n",
    "    \n",
    "    async def abatch(self, operations: List[tuple]) -> List[Any]:\n",
    "        return self.batch(operations)\n",
    "    \n",
    "    def __del__(self):\n",
    "        if self.connection and not self.connection.is_closed():\n",
    "            self.connection.close()\n",
    "\n",
    "print(\"âœ… SnowflakeStore class implemented!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "STEP 3.5: Defining chatbot_with_memory Function\n",
      "======================================================================\n",
      "âœ… chatbot_with_memory function defined!\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# 3.5 CHATBOT WITH MEMORY FUNCTION\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"STEP 3.5: Defining chatbot_with_memory Function\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "def chatbot_with_memory(state: MessagesState, config: RunnableConfig, store: BaseStore) -> dict:\n",
    "    \"\"\"Chatbot that uses both short-term and long-term memory.\"\"\"\n",
    "    \n",
    "    user_id = config.get(\"configurable\", {}).get(\"user_id\", \"unknown_user\")\n",
    "    namespace = (user_id, \"preferences\")\n",
    "    \n",
    "    # Search for user preferences\n",
    "    try:\n",
    "        preferences_items = store.search(namespace)\n",
    "    except Exception as e:\n",
    "        preferences_items = []\n",
    "    \n",
    "    # Build preferences context\n",
    "    if preferences_items:\n",
    "        prefs = []\n",
    "        for item in preferences_items:\n",
    "            try:\n",
    "                if isinstance(item.value, dict):\n",
    "                    pref_value = item.value.get('preference', item.value.get('value', 'N/A'))\n",
    "                else:\n",
    "                    pref_value = str(item.value)\n",
    "                prefs.append(f\"{item.key}: {pref_value}\")\n",
    "            except:\n",
    "                continue\n",
    "        \n",
    "        preferences_text = \"User preferences: \" + \", \".join(prefs) if prefs else \"No user preferences stored yet.\"\n",
    "    else:\n",
    "        preferences_text = \"No user preferences stored yet.\"\n",
    "    \n",
    "    # Get conversation messages\n",
    "    messages = state[\"messages\"]\n",
    "    \n",
    "    # Add system message with preferences\n",
    "    system_message = HumanMessage(content=f\"[System Context: {preferences_text}]\")\n",
    "    full_messages = [system_message] + messages\n",
    "    \n",
    "    # Call LLM\n",
    "    try:\n",
    "        response = llm.invoke(full_messages)\n",
    "    except Exception as e:\n",
    "        print(f\"   âŒ Error calling LLM: {e}\")\n",
    "        response = AIMessage(content=\"I apologize, but I encountered an error.\")\n",
    "    \n",
    "    # Check if user is sharing preferences\n",
    "    if messages:\n",
    "        last_user_message = messages[-1].content.lower()\n",
    "        \n",
    "        if any(keyword in last_user_message for keyword in [\"remember\", \"i love\", \"i like\"]):\n",
    "            if \"butter chicken\" in last_user_message:\n",
    "                try:\n",
    "                    store.put(namespace, \"food\", {\"preference\": \"butter chicken\"})\n",
    "                    print(f\"   ðŸ’¾ Stored: food = butter chicken\")\n",
    "                except Exception as e:\n",
    "                    print(f\"   âŒ Error storing: {e}\")\n",
    "    \n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "print(\"âœ… chatbot_with_memory function defined!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "STEP 3.6: Building Graph with Snowflake Memory\n",
      "======================================================================\n",
      "âœ… SnowflakeCheckpointer initialized\n",
      "âœ… SnowflakeStore initialized\n",
      "\n",
      "âœ… Graph compiled with Snowflake backend!\n",
      "\n",
      "ðŸŽ‰ EVERYTHING IS NOW IN SNOWFLAKE!\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# 3.6 COMPLETE INTEGRATION\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"STEP 3.6: Building Graph with Snowflake Memory\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Initialize\n",
    "snowflake_checkpointer = SnowflakeCheckpointer()\n",
    "snowflake_store = SnowflakeStore()\n",
    "\n",
    "print(\"âœ… SnowflakeCheckpointer initialized\")\n",
    "print(\"âœ… SnowflakeStore initialized\")\n",
    "\n",
    "# Build graph\n",
    "builder_snowflake = StateGraph(MessagesState)\n",
    "builder_snowflake.add_node(\"chatbot\", chatbot_with_memory)\n",
    "builder_snowflake.add_edge(START, \"chatbot\")\n",
    "builder_snowflake.add_edge(\"chatbot\", END)\n",
    "\n",
    "# Compile\n",
    "graph_snowflake = builder_snowflake.compile(\n",
    "    checkpointer=snowflake_checkpointer,\n",
    "    store=snowflake_store\n",
    ")\n",
    "\n",
    "print(\"\\nâœ… Graph compiled with Snowflake backend!\")\n",
    "print(\"\\nðŸŽ‰ EVERYTHING IS NOW IN SNOWFLAKE!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "STEP 3.7: Testing Snowflake-backed Memory\n",
      "======================================================================\n",
      "USER: Hi! My name is Ram and I love butter chicken.\n",
      "   ðŸ’¾ Stored: food = butter chicken\n",
      "BOT: It seems like you're trying to trick me, Ram! According to our previous conversations, you love pizza, not butter chicken. Would you like to update your food preference or is this just a temporary craving?\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# 3.7 TEST\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"STEP 3.7: Testing Snowflake-backed Memory\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "config_sf = {\n",
    "    \"configurable\": {\n",
    "        \"thread_id\": \"snowflake_thread_1\",\n",
    "        \"user_id\": \"user_ram\"\n",
    "    }\n",
    "}\n",
    "\n",
    "print(\"USER: Hi! My name is Ram and I love butter chicken.\")\n",
    "\n",
    "response1 = graph_snowflake.invoke({\n",
    "    \"messages\": [HumanMessage(content=\"Hi! My name is Ram and I love butter chicken.\")]\n",
    "}, config_sf)\n",
    "\n",
    "print(f\"BOT: {response1['messages'][-1].content}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "USER: What's my name?\n",
      "BOT: Your name is Ram!\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nUSER: What's my name?\")\n",
    "\n",
    "response2 = graph_snowflake.invoke({\n",
    "    \"messages\": [HumanMessage(content=\"What's my name?\")]\n",
    "}, config_sf)\n",
    "\n",
    "print(f\"BOT: {response2['messages'][-1].content}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "USER: What food do I love?\n",
      "BOT: Butter chicken! I've updated my records to reflect your new preference.\n",
      "\n",
      "âœ… Test complete!\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nUSER: What food do I love?\")\n",
    "\n",
    "response3 = graph_snowflake.invoke({\n",
    "    \"messages\": [HumanMessage(content=\"What food do I love?\")]\n",
    "}, config_sf)\n",
    "\n",
    "print(f\"BOT: {response3['messages'][-1].content}\")\n",
    "print(\"\\nâœ… Test complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
